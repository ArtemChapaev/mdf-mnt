{"cells":[{"cell_type":"code","execution_count":null,"id":"314d05e7","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"314d05e7","outputId":"159ca800-2fcb-413d-8258-e838e131fd6a","executionInfo":{"status":"ok","timestamp":1739093199368,"user_tz":-180,"elapsed":6768,"user":{"displayName":"Артем Чапаев","userId":"16269375557667854029"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting razdel\n","  Downloading razdel-0.5.0-py3-none-any.whl.metadata (10.0 kB)\n","Downloading razdel-0.5.0-py3-none-any.whl (21 kB)\n","Installing collected packages: razdel\n","Successfully installed razdel-0.5.0\n"]}],"source":["!pip install razdel"]},{"cell_type":"code","execution_count":null,"id":"r7IxI-ScLusj","metadata":{"id":"r7IxI-ScLusj"},"outputs":[],"source":["import os\n","import json\n","\n","import pandas as pd\n","from transformers import BertModel, BertTokenizerFast"]},{"cell_type":"code","execution_count":null,"id":"59c49e30","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"59c49e30","outputId":"767a87dc-7337-4c71-bfef-af945f2bfb14","executionInfo":{"status":"ok","timestamp":1739093303279,"user_tz":-180,"elapsed":68805,"user":{"displayName":"Артем Чапаев","userId":"16269375557667854029"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["!ls drive/MyDrive/diploma/data"],"metadata":{"id":"I0OJCbUkFsQ5"},"id":"I0OJCbUkFsQ5","execution_count":null,"outputs":[]},{"cell_type":"code","source":["from utils import clean_text, is_text_valid"],"metadata":{"id":"sv2cYKdQ6qMR"},"id":"sv2cYKdQ6qMR","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"id":"22790625","metadata":{"id":"22790625"},"outputs":[],"source":["DATA_PATH_PREFIX = 'drive/MyDrive/diploma/data/'"]},{"cell_type":"code","execution_count":null,"id":"ZzMNPPypLusm","metadata":{"id":"ZzMNPPypLusm"},"outputs":[],"source":["MODEL_PATH = 'drive/MyDrive/diploma/labse_moksha_40k+5k'"]},{"cell_type":"markdown","id":"9b5ac2ab","metadata":{"id":"9b5ac2ab"},"source":["# Align and save parallel pairs for each document"]},{"cell_type":"code","source":["from align_sentences import align_sentences"],"metadata":{"id":"6PE6xdDZLhVD"},"id":"6PE6xdDZLhVD","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"id":"PmRxzirdE5Kb","metadata":{"id":"PmRxzirdE5Kb","collapsed":true},"outputs":[],"source":["model = BertModel.from_pretrained(MODEL_PATH)\n","tokenizer = BertTokenizerFast.from_pretrained(MODEL_PATH)"]},{"cell_type":"code","source":["model.cuda();"],"metadata":{"id":"iwsWXR2FbwOH"},"id":"iwsWXR2FbwOH","execution_count":null,"outputs":[]},{"cell_type":"code","source":["def get_mdf_ru_texts(texts: dict[str, str], key: str) -> tuple[str, str]:\n","    \"\"\"\n","    Retrieves Moksha (mdf) and Russian (ru) text pairs based on the given key.\n","\n","    Args:\n","        texts (dict[str, str]): A dictionary containing text pairs.\n","        key (str): The text key, which should start with 'mdf' or 'ru'.\n","\n","    Returns:\n","        tuple[str|None, str|None]: A tuple containing the Moksha and Russian text or tuple contaning Nones.\n","\n","    Raises:\n","        RuntimeError: If the key does not start with 'mdf' or 'ru', or if an unexpected key format is encountered.\n","    \"\"\"\n","    # Ensure the key is relevant (should start with 'mdf' or 'ru')\n","    if not key.startswith('mdf') and not key.startswith('ru'):\n","        raise RuntimeError(\"Invalid key format\")\n","\n","    # Process only Moksha (mdf) keys to avoid duplicate handling\n","    if not key.startswith('mdf'):\n","        return None, None\n","\n","    # If the key is simple ('mdf'/'ru'), return the corresponding texts\n","    key_parts = key.split('_')\n","    if len(key_parts) == 1:\n","        return texts['mdf'], texts['ru']\n","\n","    # If the key has an index, retrieve the corresponding indexed texts\n","    if len(key_parts) == 2:\n","        return texts[f'mdf_{key_parts[1]}'], texts[f'ru_{key_parts[1]}']\n","\n","    # Raise an error if the key format is unexpected\n","    raise RuntimeError(\"Unexpected key format\")\n"],"metadata":{"id":"9M4oKU8sLneJ"},"id":"9M4oKU8sLneJ","execution_count":null,"outputs":[]},{"cell_type":"code","source":["def align_wikisource_doc(filename: str, print_non_parallel_texts: bool = False):\n","    \"\"\"\n","    Aligns Moksha (mdf) and Russian (ru) sentences from a Wikisource document.\n","\n","    Args:\n","        filename (str): Path to the JSON file containing texts.\n","        print_non_parallel_texts (bool, optional): Whether to print non-parallel text pairs. Defaults to False.\n","\n","    Returns:\n","        list: A list of aligned sentence pairs.\n","    \"\"\"\n","    with open(filename, 'r') as f:\n","        texts = json.load(f)\n","\n","    all_aligned_pairs = []\n","\n","    for key in texts.keys():\n","        mdf_text, ru_text = get_mdf_ru_texts(texts, key)\n","\n","        if mdf_text is None or ru_text is None:\n","            continue\n","\n","        if ru_text == '' or mdf_text == '':\n","            print(f\"Empty pair: ({key}), {mdf_text}, {ru_text}\")\n","            continue\n","\n","        aligned_pairs = align_sentences(mdf_text, ru_text, model, tokenizer)\n","        all_aligned_pairs += aligned_pairs\n","\n","        if print_non_parallel_texts and not aligned_pairs:\n","            print(f\"0 aligned pairs: {key}, {mdf_text}, {ru_text}\")\n","\n","    return all_aligned_pairs"],"metadata":{"id":"DW4rr9H9pSZA"},"id":"DW4rr9H9pSZA","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"id":"578d037e","metadata":{"id":"578d037e"},"outputs":[],"source":["for filename in os.listdir(DATA_PATH_PREFIX + 'texts_for_align/'):\n","    if not filename.endswith('.json'):\n","        continue\n","\n","    book = '.'.join(filename.split('.')[:-1])\n","    print(f\"{book=}\")\n","\n","    all_aligned_pairs = align_wikisource_doc(\n","        DATA_PATH_PREFIX + f'texts_for_align/{filename}'\n","    )\n","    print(f\"{len(all_aligned_pairs)=}\")\n","\n","    data = []\n","    for mdf, ru in all_aligned_pairs:\n","        cleaned_mdf = clean_text(mdf)\n","        cleaned_ru = clean_text(ru)\n","\n","        if not is_text_valid(cleaned_mdf) or not is_text_valid(cleaned_ru):\n","            continue\n","\n","        data.append({'mdf': cleaned_mdf, 'ru': cleaned_ru})\n","\n","    with open(DATA_PATH_PREFIX + f'aligned_{book}_sents_09_02.json', \"w\") as file:\n","        json.dump(data, file, ensure_ascii=False, indent=4)\n","\n","    print()"]},{"cell_type":"code","source":[],"metadata":{"id":"Les-4f1_DhgM"},"id":"Les-4f1_DhgM","execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.9"}},"nbformat":4,"nbformat_minor":5}